---
title: "Acoustic Emotion Classification"
subtitle: "accuracy of unsupervised methods for emotion recognition from acoustic features"
author: 
  - name: "Ralph Andrade"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "An emotion classification project using machine learning to identify six emotions from speech audio recordings, comparing different algorithms to determine the most effective approach for acoustic emotion recognition."
title-slide-attributes:
  data-background-image: images/charts/abstract-acoustics.png
  data-background-size: stretch
  data-background-opacity: "0.5"
  data-slide-number: none
format:
  revealjs:
    theme:  ['data/customtheming.scss']
    code-tools: true
    code-fold: true
    code-overflow: wrap
    embed-resources: true
editor: visual
jupyter: python3
execute:
  echo: false
---

```{python}
#| label: load-packages
#| include: false

# Import libs
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

```



```{python}
#| label: load-data
#| include: false
# Load data in Python

df = pd.read_csv("./data/crema_d.csv", index_col=0)
```

## Abstract

-   Dataset: CREMA-D, six emotions (neutral, happy, sad, angry, fear, disgust)
-   Features: librosa, standardized, PCA (98% variance)
-   Models: SVM, Random Forest, MLP
-   MLP achieved macro F1-score: 0.5534

## Introduction

-   Automatic emotion classification is challenging
-   CREMA-D: 7,442 clips, 91 actors
-   Features: MFCCs, spectral properties
-   Goal: Compare traditional, ensemble, and neural networks

## Research Question

-   **Q1. What is the classification accuracy of unsupervised methods for emotion recognition from acoustic features?**
-   **Q2. How do standalone algorithms, ensemble approaches, and neural networks compare in terms of accuracy, robustness, and computational efficiency for emotion classification from audio?**

# Exploratory Analysis

## EDA

::: panel-tabset
### Data Overview

```{python}
#| label: dataset
#| echo: true

# number of variables and observations in the data
print(f"Total observations: {df.shape[0]}")
print(f"Number of features: {df.shape[1]}")

# missing values in each column
missing_df = df.isna().sum()
print("Numeric Description:\n", df.describe())
```

### Target Distribution

![Target Class Count Plot](images/charts/1-Target-histogram.png){fig-align="left" width="555"}
:::

## Data Preprocessing

::: panel-tabset
### Data Preparation

-   Remove irrelevant columns, handle missing values
-   Apply Yeo-Johnson Power Transformation for numeric skew
-   Encode target labels

### Skewness Transformation

![Sknewness Before & After Yeo Johnson Transformation](images/charts/2-yeo-johnson-before-after.png){fig-align="left"}
:::

## Feature engineering

::: r-fit-text
-   **Spectral Contrast:** Measures amplitude differences between spectral peaks and valleys, capturing timbral characteristics that distinguish emotional expressions
-   **MFCCs (Mel-frequency cepstral coefficients):** Extract 13 coefficients representing the short-term power spectrum, fundamental for speech emotion recognition
-   **Chroma Features:** Capture pitch class energy distribution, providing harmonic content information relevant to emotional prosody
-   **Zero-Crossing Rate:** Quantifies signal noisiness by measuring zero-axis crossings, distinguishing between voiced and unvoiced speech segments
-   **Root Mean Square (RMS) Energy:** Measures overall signal energy, correlating with loudness and emotional intensity
:::

## Principal Component Analysis

![PCA: retain 98% variance](images/charts/3-scree-plot.png){fig-align="left"}

# Model Training & Evaluation

## Model Evaulation Function

:::::: r-fit-text
::::: columns
::: {.column width="50%"}
-   Inputs:
    -   model → ML model instance (Random Forest, SVM, MLP)
    -   X_train, X_test → feature matrices
    -   y_train, y_test → labels
    -   model_name → string for labeling outputs
:::

::: {.column width="50%"}
-   Output:
    -   Console print of metrics & confusion matrix
    -   Dictionary with overall and per-class performance
:::
:::::
::::::

# Model Comparison

## Model Performance

::: r-fit-text
| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| RF    | 0.52     | 0.51      | 0.515  | 0.512    |
| SVM   | 0.49     | 0.48      | 0.487  | 0.482    |
| MLP   | 0.557    | 0.554     | 0.557  | 0.553    |
:::

## Model Metric Comparison

![Model Metric (Accuracy, Precision, Recall, F1-Score) Comparison](images/charts/7-Model-Comparision.png){fig-align="left"}

# Model Prediction

## Random Forest Predictions

![Random Forest; Confusion Matrix](images/charts/4-RF-CM.png){fig-align="left"}

## Support Vector Machine Predictions

![Support Vector Machine; Confusion Matrix](images/charts/5-SVM-CM.png){fig-align="left"}

## Multi Layer Perceptron Predictions

![Multi Layer Perceptron; Confusion Matrix](images/charts/6-MLP-CM.png){fig-align="left"}

# Conclusion

## Summary
-   MLP is the best-performing model for multi-class emotion recognition
-   Neural networks capture complex, non-linear patterns better than traditional or ensemble methods
-   Future Work: temporal modeling, multimodal integration, advanced feature extraction