---
title: "Acoustic Emotion Classification"
subtitle: "Optimizing Performance Through Ensemble Methods"
author: 
  - name: "Ralp Andrade"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "An emotion classification project using machine learning to identify four emotions (happy, sad, angry, fear) from speech audio recordings, comparing different algorithms to determine the most effective approach for acoustic emotion recognition."
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
  echo: false
jupyter: python3
---

## Abstract
This project investigates the fundamental capability of machine learning models to distinguish emotional states through acoustic feature analysis. Using the CREMA-D (Crowd-Sourced Emotional Multimodal Actors Dataset), our study focuses on the classification emotions: neutral, happy, sad, angry, fear, disgust. A combination of traditional feature engineering paired with ensemble learning methods forms the basis for developing robust emotion recognition models. We systematically examine and compare the predictive performance of individual algorithms with ensemble and neural network strategies for multi-class emotion recognition.

## Introduction

Building on the challenge of automatic emotion classification, this project leverages the Crowd-Sourced Emotional Multimodal Actors Dataset (CREMA-D), a widely recognized collection of acted speech designed for emotion research. The dataset comprises 7,442 `.wav` clips from 91 actors portraying six basic emotions. Existing research shows that while audio features like MFCCs and spectral properties are often used for emotion detection, there is still no agreement on the best feature selection or model designs, especially in traditional machine learning contexts. (Banerjee, Huang, & Lettiere, n.d.). We transformed raw audio signals into quantitative features using the `librosa` library, as detailed in our [proposal](https://info-523-su25.github.io/final-project-etlflow/proposal.html).

Project's goal is to explore the effectiveness of unsupervised learning for predicting multi-class emotion targets, aiming to benchmark these results from ensemble strategies against standalone and neural network models. This methodology offers new perspective on the relative utility of unsupervised techniques in speech emotion recognition.
